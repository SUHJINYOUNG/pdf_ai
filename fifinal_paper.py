import streamlit as st
import zipfile
import os
import tempfile
from PyPDF2 import PdfReader
import google.generativeai as genai

# Gemini API ì„¤ì •
genai.configure(api_key="AIzaSyCN9aElRlN1VoATgzoo6Spx2RPsp67nEbc")
model = genai.GenerativeModel("gemini-1.5-flash")

st.set_page_config(page_title="PDF Chat ë¶„ì„ê¸°", layout="wide")

st.title("ğŸ“¦ ZIP ê¸°ë°˜ PDF Chat ë¶„ì„ ì‹œìŠ¤í…œ")

# ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì— chat_history ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # list of dicts: {"role": "user"/"assistant", "text": ...}

uploaded_zip = st.file_uploader("PDF íŒŒì¼ë“¤ì´ ë“¤ì–´ìˆëŠ” ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["zip"])
question = st.text_input("AIì—ê²Œ ë¬¼ì–´ë³¼ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")

def extract_text_from_pdf(path):
    reader = PdfReader(path)
    texts = []
    for page in reader.pages:
        try:
            texts.append(page.extract_text() or "")
        except:
            continue
    return "\n".join(texts)

# ë©”ì¸ ë²„íŠ¼
if st.button("ì§ˆë¬¸í•˜ê¸°"):
    if not uploaded_zip:
        st.warning("ZIP íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    elif not question:
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤â€¦"):
            try:
                # 1) ZIPì—ì„œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
                context_list = []
                with tempfile.TemporaryDirectory() as tmpdir:
                    with zipfile.ZipFile(uploaded_zip, "r") as zf:
                        zf.extractall(tmpdir)

                    for fname in sorted(os.listdir(tmpdir)):
                        if not fname.lower().endswith(".pdf"):
                            continue
                        path = os.path.join(tmpdir, fname)
                        text = extract_text_from_pdf(path).strip()
                        if not text:
                            snippet = f"ğŸ“„ {fname}: (í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë¹ˆ ë¬¸ì„œ)"
                        else:
                            # ë„ˆë¬´ ê¸¸ë©´ ì•/ë’¤ 1,000ìë§Œ
                            if len(text) > 2000:
                                snippet = (
                                    f"ğŸ“„ {fname}\n"
                                    + text[:1000]
                                    + "\n\n...[ì¤‘ëµ]...\n\n"
                                    + text[-1000:]
                                )
                            else:
                                snippet = f"ğŸ“„ {fname}\n{text}"
                        context_list.append(snippet)

                full_context = "\n\n---\n\n".join(context_list)

                # 2) Gemini í˜¸ì¶œ
                prompt = f"""
ì•„ë˜ëŠ” ZIPì— í¬í•¨ëœ ì—¬ëŸ¬ PDF ë¬¸ì„œì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.

{full_context}

[ì§ˆë¬¸]
{question}
"""
                response = model.generate_content(prompt)

                # 3) ì„¸ì…˜ì— ê¸°ë¡
                st.session_state.chat_history.append({"role": "user", "text": question})
                st.session_state.chat_history.append({"role": "assistant", "text": response.text})

            except Exception as e:
                st.error(f"â— ì˜¤ë¥˜ ë°œìƒ: {e}")

# 4) ì±„íŒ… íˆìŠ¤í† ë¦¬ ë Œë”ë§
for msg in st.session_state.chat_history:
    if msg["role"] == "user":
        st.chat_message("user").write(msg["text"])
    else:
        st.chat_message("assistant").write(msg["text"])
